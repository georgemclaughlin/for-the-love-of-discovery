"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[425],{2827:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});var o=t(5893),a=t(1151);const s={slug:"microsoft-autogen-prompts",title:"Microsoft AutoGen Prompts",authors:["gmclaughlin"],tags:["llm","autogen","feasibility"]},r=void 0,i={permalink:"/for-the-love-of-discovery/microsoft-autogen-prompts",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-01-15-autogen-prompts.mdx",source:"@site/blog/2024-01-15-autogen-prompts.mdx",title:"Microsoft AutoGen Prompts",description:"Microsoft AutoGen is a promising framework aimed at solving problems using a multi-agent setup. It offers some interesting features such as code execution and group chat. This blog aims to demystify the prompts that power AutoGen.",date:"2024-01-15T00:00:00.000Z",formattedDate:"January 15, 2024",tags:[{label:"llm",permalink:"/for-the-love-of-discovery/tags/llm"},{label:"autogen",permalink:"/for-the-love-of-discovery/tags/autogen"},{label:"feasibility",permalink:"/for-the-love-of-discovery/tags/feasibility"}],readingTime:15.03,hasTruncateMarker:!0,authors:[{name:"George McLaughlin",title:"Curious tech professional",url:"https://www.linkedin.com/in/georgefmclaughlin/",imageURL:"https://raw.githubusercontent.com/georgemclaughlin/for-the-love-of-discovery/main/img/gmclaughlin.jpg",key:"gmclaughlin"}],frontMatter:{slug:"microsoft-autogen-prompts",title:"Microsoft AutoGen Prompts",authors:["gmclaughlin"],tags:["llm","autogen","feasibility"]},unlisted:!1},l={authorsImageUrls:[void 0]},d=[{value:"Quick Start Breakdown",id:"quick-start-breakdown",level:2},{value:"First Round",id:"first-round",level:3},{value:"Looping",id:"looping",level:3},{value:"Last Pass",id:"last-pass",level:3},{value:"Prompt Overriding",id:"prompt-overriding",level:3},{value:"Group Chat with Chat Manager Breakdown",id:"group-chat-with-chat-manager-breakdown",level:2},{value:"Speaker Selection",id:"speaker-selection",level:3},{value:"Chat Flow",id:"chat-flow",level:3},{value:"Thoughts",id:"thoughts",level:3},{value:"Summary",id:"summary",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://microsoft.github.io/autogen/",children:"Microsoft AutoGen"})," is a promising framework aimed at solving problems using a multi-agent setup. It offers some interesting features such as code execution and group chat. This blog aims to demystify the prompts that power AutoGen."]}),"\n",(0,o.jsx)(n.h2,{id:"quick-start-breakdown",children:"Quick Start Breakdown"}),"\n",(0,o.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant AutoGen\n    participant LLM\n    AutoGen->>LLM: system prompt + task\n    LLM--\x3e>AutoGen: Run this code\n    AutoGen->>AutoGen: Runs code\n    loop Troubleshooting Code\n        AutoGen->>LLM: Code doesn't work\n        LLM--\x3e>AutoGen: Try this\n        AutoGen->>AutoGen: Runs code\n    end\n    AutoGen->>LLM: Success\n    LLM--\x3e>AutoGen: Looks like we are done here"}),"\n",(0,o.jsx)(n.h3,{id:"first-round",children:"First Round"}),"\n",(0,o.jsx)(n.p,{children:"Let's start with the Quick Start example."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n\n# Load LLM inference endpoints from an env variable or a file\n# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints\n# and OAI_CONFIG_LIST_sample.json\nconfig_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")\nassistant = AssistantAgent("assistant", llm_config={"config_list": config_list})\nuser_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"})\nuser_proxy.initiate_chat(assistant, message="Plot a chart of NVDA and TESLA stock price change YTD.")\n# This initiates an automated chat between the two agents to solve the task\n'})}),"\n",(0,o.jsxs)(n.p,{children:["A prompt is constructed using the user_proxy message and the AssistantAgent's ",(0,o.jsx)(n.a,{href:"https://github.com/microsoft/autogen/blob/a122ffe5413aef69b29ce89861056ce9051409c3/autogen/agentchat/assistant_agent.py#L17",children:"default system_message"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-plain",metastring:'title="default system_message"',children:"Solve tasks using your coding and language skills.\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\nSolve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\nWhen using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\nIf you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\nWhen you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\nReply \"TERMINATE\" in the end when everything is done.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="user_proxy message"',children:"Plot a chart of NVDA and TESLA stock price change YTD.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="messages object passed to LLM"',children:'{\n    "messages": [\n        {\n            "content": "You are a helpful AI assistant.\\nSolve tasks using your coding and language skills.\\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\\n    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\\n    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\\nSolve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\\nWhen using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can\'t modify your code. So do not suggest incomplete code which requires users to modify. Don\'t use a code block if it\'s not intended to be executed by the user.\\nIf you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don\'t include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use \'print\' function for the output when relevant. Check the execution result returned by the user.\\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can\'t be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\\nWhen you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\\nReply \\"TERMINATE\\" in the end when everything is done.\\n    ",\n            "role": "system"\n        },\n        {\n            "content": "Plot a chart of NVDA and TESLA stock price change YTD.",\n            "name": "User_proxy",\n            "role": "user"\n        }\n    ]\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"The language model returns a response, and in this case, it is some python code for us to run."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="LLM Response"',children:"To plot a chart of NVDA and Tesla stock price change Year-to-Date (YTD), I will use Python with the `pandas` and `yfinance` libraries to fetch the stock data and `matplotlib` for plotting the chart.\nHere's the Python code to accomplish this task:\n```python\n# filename: stock_price_chart.py\nimport yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Downloading NVDA and TSLA stock data\nnvda = yf.download('NVDA', start='2022-01-01')\ntesla = yf.download('TSLA', start='2022-01-01')\n\n# Calculating YTD percentage change\nnvda['YTD Change'] = nvda['Close'] / nvda['Close'].iloc[0] * 100 - 100\ntesla['YTD Change'] = tesla['Close'] / tesla['Close'].iloc[0] * 100 - 100\n\n# Plotting the YTD percentage change\nplt.figure(figsize=(12, 6))\nplt.plot(nvda.index, nvda['YTD Change'], label='NVDA')\nplt.plot(tesla.index, tesla['YTD Change'], label='TSLA')\nplt.title('YTD Stock Price Change')\nplt.xlabel('Date')\nplt.ylabel('Percentage Change')\nplt.legend()\nplt.show()\n```\n\nPlease run the provided Python script, and it will produce a chart showing the YTD stock price change for NVDA and TSLA.\n\nAfter running the code, please confirm if the chart is generated successfully.\n\nTERMINATE\n"})}),"\n",(0,o.jsx)(n.p,{children:"Our local environment runs the Python code and it results in an error (as expected)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",metastring:'title="Local process text"',children:'exitcode: 1 (execution failed)\nCode output: \nTraceback (most recent call last):\n  File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py", line 3489, in <module>\n      main()\n        File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py", line 3482, in main\n            globals = debugger.run(setup[\'file\'], None, None, is_module)\n              File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py", line 2510, in run\n                  return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)\n                    File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py", line 2517, in _exec\n                        globals = pydevd_runpy.run_path(file, globals, \'__main__\')\n                          File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 321, in run_path\n                              return _run_module_code(code, init_globals, run_name,\n                                File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 135, in _run_module_code\n                                    _run_code(code, mod_globals, init_globals,\n                                      File "/root/.vscode-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code\n                                          exec(code, run_globals)\n                                            File "", line 1, in <module>\n                                                import matplotlib.pyplot as plt\n                                                ModuleNotFoundError: No module named \'matplotlib\'\n\n'})}),"\n",(0,o.jsx)(n.h3,{id:"looping",children:"Looping"}),"\n",(0,o.jsxs)(n.p,{children:["This error is then appended to the conversation and sent back to the language model. This back and forth continues.\nNote, the error we just appended to the conversation was about ",(0,o.jsx)(n.strong,{children:"~500 tokens"}),". Knowing that, you may run into limits with models (such as gpt-3.5-turbo with 4,096 token context limit) whose contexts are not much larger than that."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="Error with gpt-3.5-turbo"',children:"Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens. However, your messages resulted in 4221 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"last-pass",children:"Last Pass"}),"\n",(0,o.jsx)(n.p,{children:"We pass back the final output of our program to the LLM."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="last message passed to LLM"',children:"exitcode: 0 (execution succeeded)\nCode output: \n\n"})}),"\n",(0,o.jsx)(n.p,{children:"With our final response being"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="LLM Response"',children:"The code executed successfully without any errors. You should now see a chart displaying the Year-to-Date (YTD) stock price change for NVDA and TSLA. If everything looks good, then the task is complete.\n\nTERMINATE\n"})}),"\n",(0,o.jsx)(n.p,{children:"Awesome!"}),"\n",(0,o.jsx)(n.h3,{id:"prompt-overriding",children:"Prompt Overriding"}),"\n",(0,o.jsx)(n.p,{children:"If you are challenged with a different task or find that your model is struggling, the system_message can be defined at the start."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'assistant = AssistantAgent("assistant", llm_config={"config_list": config_list}, system_message:"Be good to humans.")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"group-chat-with-chat-manager-breakdown",children:"Group Chat with Chat Manager Breakdown"}),"\n",(0,o.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant AutoGen\n    participant Chat Manager\n    participant Product Manager\n    participant Speaker XYZ\n    AutoGen->>Chat Manager: role playing prompt + task + speaker selection prompt\n    Chat Manager--\x3e>AutoGen: Product Manager\n    AutoGen->>Product Manager: system_message + task\n    Product Manager--\x3e>AutoGen: response\n    loop Task Solving\n        AutoGen ->>Chat Manager: role playing prompt + task + Agent Conversation so far + speaker selection prompt\n        Chat Manager--\x3e>AutoGen: Speaker XYZ\n        AutoGen->>Speaker XYZ: respond to this\n        Speaker XYZ->>AutoGen: response\n    end\n    Chat Manager --\x3e> AutoGen: Looks like we are done here"}),"\n",(0,o.jsx)(n.p,{children:"While very verbose, the single agent back and forth is straight forward. Let's take a look at how AutoGen manages a group chat."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, GroupChat, GroupChatManager\n\nconfig_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")\nuser_proxy = UserProxyAgent(\n    name="User_proxy",\n    description="A human admin.",\n    code_execution_config={"last_n_messages": 2, "work_dir": "groupchat"},\n    human_input_mode="TERMINATE",\n)\nassistant = AssistantAgent("assistant", llm_config={"config_list": config_list})\ncoder = AssistantAgent(\n    name="Coder",\n    description="Talended software developer skilled at writing code",\n    llm_config={"config_list": config_list}\n)\npm = AssistantAgent(\n    name="Product_manager",\n    description="Creative in software product ideas.",\n    llm_config={"config_list": config_list}\n)\ngroupchat = GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\nmanager = GroupChatManager(groupchat=groupchat, llm_config={"config_list": config_list})\nuser_proxy.initiate_chat(\n    manager, message="Find a latest paper about gpt-4 on arxiv and find its potential applications in software."\n)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"speaker-selection",children:"Speaker Selection"}),"\n",(0,o.jsx)(n.p,{children:"The chat begins by us asking the group chat manager who should speak. They are given the name and descriptions of the agents in the chat."}),"\n",(0,o.jsx)(n.p,{children:"3 messages are pieced together"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="role playing prompt"',children:"You are in a role play game. The following roles are available:\nUser_proxy: A human admin.\nCoder: Talended software developer skilled at writing code\nProduct_manager: Creative in software product ideas..\n\nRead the following conversation.\nThen select the next role from ['User_proxy', 'Coder', 'Product_manager'] to play. Only return the role.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="Our user_proxy message"',children:"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="speaker selection prompt"',children:"Read the above conversation. Then select the next role from ['User_proxy', 'Coder', 'Product_manager'] to play. Only return the role.\n"})}),"\n",(0,o.jsx)(n.h3,{id:"chat-flow",children:"Chat Flow"}),"\n",(0,o.jsx)(n.p,{children:"The LLM Group Manager selected the Product_manager and is give these two messages."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"You are a helpful AI assistant.\nSolve tasks using your coding and language skills.\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n    Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n    When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n    If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n    If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n    When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n    Reply \"TERMINATE\" in the end when everything is done.\n\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="Our user_proxy message"',children:"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n"})}),"\n",(0,o.jsx)(n.p,{children:"The Group Manager is once again queried to select the next speaker."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"You are in a role play game. The following roles are available:\nUser_proxy: A human admin.\nCoder: Talended software developer skilled at writing code\nProduct_manager: Creative in software product ideas..\n\nRead the following conversation.\nThen select the next role from ['User_proxy', 'Coder', 'Product_manager'] to play. Only return the role.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",metastring:'title="Product_manager response"',children:'\nTo find the latest paper about GPT-4 on arXiv, you can use the following command in your terminal or command prompt:\n\n`search_query="GPT-4" arxiv_search`\n\nThis will search for the latest papers related to GPT-4 on arXiv.\n\nOnce you have the list of papers, you can check the abstract and introduction sections to find potential applications in software.\n\nHere\'s an example of a paper with potential applications in software:\n\nTitle: "GPT-4: A Generative Model for Software Development\n\nAuthors: [List of authors]\n\nAbstract:\n\nIn this paper, we propose GPT-4, a generative model for software development that uses a transformer architecture to generate code snippets. Our model is trained on a large corpus of open-source code and can generate code in a variety of programming languages. We evaluate the effectiveness of GPT-4 through a series of experiments and show that it can generate code that is comparable in quality to human-written code. We also discuss potential applications of GPT-4 in software development, including code completion, code search, and code generation for low-code platforms.\n\nIntroduction:\n\nSoftware development is a complex and time-consuming task that requires a high degree of skill and expertise. One way to improve the efficiency and effectiveness of software development is to use machine learning models to automate certain tasks. In recent years, there has been a growing interest in using generative models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), to generate code. These models have shown promising results in generating code snippets, but they have limitations in terms of their ability to generate coherent and functional code.\n\nIn this paper, we propose GPT-4, a generative model for software development that uses a transformer architecture to generate code snippets. Our model is trained on a large corpus of open-source code and can generate code in a variety of programming languages. We evaluate the effectiveness of GPT-4 through a series of experiments and show that it can generate code that is comparable in quality to human-written code.\n\nPotential applications of GPT-4 in software development include:\n\n1. Code completion: GPT-4 can be used to complete partially written code, saving developers time and effort.\n2. Code search: GPT-4 can be used to search for relevant code snippets in a large codebase, making it easier for developers to find and reuse existing code.\n3. Code generation for low-code platforms: GPT-4 can be used to generate code for low-code platforms, making it easier for non-technical users to create software applications.\n\nTo use GPT-4, developers can simply provide a prompt or a starting code snippet, and the model will generate the rest of the code. The generated code can be customized to fit the specific needs of the project, and it can be integrated into existing software development workflows.\n\nIn summary, GPT-4 is a powerful tool for software development that has the potential to revolutionize the way we develop software. Its ability to generate coherent and functional code can save developers time and effort, and its flexibility makes it a valuable tool for a wide range of software development tasks.\n\nTERMINATE\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"Read the above conversation. Then select the next role from ['User_proxy', 'Coder', 'Product_manager'] to play. Only return the role.\n"})}),"\n",(0,o.jsx)(n.h3,{id:"thoughts",children:"Thoughts"}),"\n",(0,o.jsx)(n.p,{children:"You may run into some challenges regarding the context length. The Chat Manager is only given the role descriptions in the first message, so when there are sufficient number of agent back and forths, they may end up only relying on the role name given in the last message."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Prompt with roles and descriptions for those roles (",(0,o.jsx)(n.a,{href:"https://microsoft.github.io/autogen/docs/reference/agentchat/groupchat#select_speaker_msg",children:"can be overridden"}),")"]}),"\n",(0,o.jsx)(n.li,{children:"A whole bunch of chatting"}),"\n",(0,o.jsxs)(n.li,{children:["Prompt to pick the role (no description) (",(0,o.jsx)(n.a,{href:"https://microsoft.github.io/autogen/docs/reference/agentchat/groupchat#select_speaker_prompt",children:"can be overridden"}),")"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Addiitonaly, the ",(0,o.jsx)(n.a,{href:"https://microsoft.github.io/autogen/docs/reference/agentchat/groupchat#groupchat-objects",children:"GroupChat"})," has a speaker_selection_method parameter"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'"auto": the next speaker is selected automatically by LLM. (what we see in our example)'}),"\n",(0,o.jsx)(n.li,{children:'"manual": the next speaker is selected manually by user input.'}),"\n",(0,o.jsx)(n.li,{children:'"random": the next speaker is selected randomly.'}),"\n",(0,o.jsx)(n.li,{children:'"round_robin": the next speaker is selected in a round robin fashion, i.e., iterating in the same order as provided in agents.'}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"I hope this provides a clearer understanding of how AutoGen's refined prompting enables agents working together."})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);